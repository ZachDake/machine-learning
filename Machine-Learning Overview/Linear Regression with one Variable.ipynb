{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with One Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at housing prices in Portland:\n",
    "</br>\n",
    "\n",
    "<img src=\"Images/ml-7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation:\n",
    "\n",
    "**m** = Number of training examples\n",
    "\n",
    "**x**'s = \"input\" variable / features\n",
    "\n",
    "**y**'s = \"output\" variable / \"target\" variable\n",
    "\n",
    "**(x,y)** = one training example\n",
    "\n",
    "**($x^i, y^i$)** = the $i^{th}$ training example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation:\n",
    "\n",
    "<img src=\"Images/ml-8.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we represent h?\n",
    "\n",
    "$h_{\\theta}(x)$ = $\\theta_{0} + \\theta_{1}(x)$\n",
    "\n",
    "**shorthand:**  $h(x) = \\theta_{0} + \\theta_{1}(x)$\n",
    "\n",
    "This represents **Linear Regression** with **one** variable. \n",
    "\n",
    "Also known as **Univariate Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. Seen pictorially, it is the image above.\n",
    "\n",
    "When the target variable that we’re trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem. When y can take on only a small number of discrete values (such as if, given the living area, we wanted to predict if a dwelling is a house or an apartment, say), we call it a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function:\n",
    "\n",
    "hypothesis: $h(x) = \\theta_{0} + \\theta_{1}(x)$\n",
    "\n",
    "$\\theta_{i}'s$ = parameters\n",
    "\n",
    "how do you choose $\\theta_{i}'s$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Parameter choice effects h(x):\n",
    "</br>\n",
    "\n",
    "<img src=\"Images/ml-9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "The goal of choosing the parameters is to choose them in such a way that it fits your training data well. The idea is to choose a $\\theta_{0}, \\theta_{1}$ such that $h_{\\theta}(x)$ is close to $y$ for our training examples $(x,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads us into a minimization problem. Our goal is to choose a $\\theta_{0}$ and a $\\theta_{1}$ that minimizes $\\frac{1}{2m} \\sum_{i=1}^m (h_{\\theta}(x) - y)^2$. This is the **Mean Squared Error** or simply the **MSE**. The inside term is squared so you don't have to worry about negative factors when calculating this error, and the $\\frac{1}{2}$ is put out in front is just there to make the math a little easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function Intuition:\n",
    "\n",
    "Going forward $J(\\theta_{0},\\theta_{1})$ will represent the Mean Squared Error.\n",
    "\n",
    "#### Lets start by looking at a simplified version of this problem:\n",
    "\n",
    "In this simplified case we will set $\\theta_{0} = 0$ and as a result $h(x) = \\theta_{1}x$ and we are trying to minimize $J(\\theta_{1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now looking at $h(x)$:\n",
    "* for fixed $\\theta_{1}$ this is a function of x --- and lets set $\\theta_{1} = 1$\n",
    "* the $y's$ are $(1,1), (2,2),$ and $(3,3)$ --- these are the corrrect values we are trying to predict\n",
    "\n",
    "Moving on to the $J(\\theta_{1})$ term:\n",
    "* $\\frac{1}{2m} \\sum_{i=1}^m (h_{\\theta}(x) - y)^2$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
